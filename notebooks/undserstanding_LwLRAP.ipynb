{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/osciiart/understanding-lwlrap-sorry-it-s-in-japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LwLRAP計算関数\n",
    "# from official code https://colab.research.google.com/drive/1AgPdhSp7ttY18O3fEoHOQKlt_3HJDLi8#scrollTo=cRCaCIb9oguU\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "    \"\"\"Calculate precisions for each true class for a single sample.\n",
    "\n",
    "    Args:\n",
    "      scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "      truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "    Returns:\n",
    "      pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "      pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "        classes.\n",
    "    \"\"\"\n",
    "    num_classes = scores.shape[0]\n",
    "    pos_class_indices = np.flatnonzero(truth > 0)\n",
    "    # Only calculate precisions if there are some true classes.\n",
    "    if not len(pos_class_indices):\n",
    "        return pos_class_indices, np.zeros(0)\n",
    "    # Retrieval list of classes for this sample.\n",
    "    retrieved_classes = np.argsort(scores)[::-1]\n",
    "    # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "    class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "    class_rankings[retrieved_classes] = range(num_classes)\n",
    "    # Which of these is a true label?\n",
    "    retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "    retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "    # Num hits for every truncated retrieval list.\n",
    "    retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "    # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "    precision_at_hits = (\n",
    "            retrieved_cumulative_hits[class_rankings[pos_class_indices]] /\n",
    "            (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "    return pos_class_indices, precision_at_hits\n",
    "\n",
    "\n",
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "    \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "\n",
    "    Arguments:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "        of presence of that class in that sample.\n",
    "      scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "        test's real-valued score for each class for each sample.\n",
    "\n",
    "    Returns:\n",
    "      per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each\n",
    "        class.\n",
    "      weight_per_class: np.array of (num_classes,) giving the prior of each\n",
    "        class within the truth labels.  Then the overall unbalanced lwlrap is\n",
    "        simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "    \"\"\"\n",
    "    assert truth.shape == scores.shape\n",
    "    num_samples, num_classes = scores.shape\n",
    "    # Space to store a distinct precision value for each class on each sample.\n",
    "    # Only the classes that are true for each sample will be filled in.\n",
    "    precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "    for sample_num in range(num_samples):\n",
    "        pos_class_indices, precision_at_hits = (\n",
    "            _one_sample_positive_class_precisions(scores[sample_num, :],\n",
    "                                                  truth[sample_num, :])\n",
    "        )\n",
    "        precisions_for_samples_by_classes[sample_num, pos_class_indices] = (precision_at_hits)\n",
    "    labels_per_class = np.sum(truth > 0, axis=0)\n",
    "    weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "\n",
    "    # Form average of each column, i.e. all the precisions assigned to labels in a particular class.\n",
    "    per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) /\n",
    "                        np.maximum(1, labels_per_class))\n",
    "    # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "    #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "    #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "    #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "    return per_class_lwlrap, weight_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解ラベルが1つの場合。  \n",
    "- クラスがA,B,Cの3種類とする。\n",
    "- 正解ラベル = (A), 予測 = (A: 0.7, B: 0.1, 0.2)の場合を例として考える。\n",
    "\n",
    "\n",
    "- まず予測をランク化 (値の大きい順に数字を振る) する。-> 予測 = (A: 1, B: 3, C:2)\n",
    "- **Score = 1～正解ラベルのランクまでの正解数 / 正解ラベルのランク** と計算される。\n",
    "\n",
    "\n",
    "- この場合、\n",
    "    - 正解ラベルのランク = 1\n",
    "    - 1～正解ラベルのランクまでの正解数 = ランク1～1までの正解数 = 1 \n",
    "- なので、Score = 1/1 = 1.0 となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解ラベル [0]\n",
      "スコア [1.]\n"
     ]
    }
   ],
   "source": [
    "# 実際に計算してみる。\n",
    "y_true = np.array([1, 0, 0,])\n",
    "y_score = np.array([0.7, 0.1, 0.2])\n",
    "pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(y_score, y_true)\n",
    "print(\"正解ラベル\", pos_class_indices)\n",
    "print(\"スコア\", precision_at_hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "別例\n",
    "- 正解ラベル = (A), 予測 = (A: 0.1, B: 0.7, 0.2)の場合。\n",
    "    - ランク化予測 = (A: 3, B: 1, C:2)\n",
    "    - 正解ラベルのランク = 3\n",
    "    - 1～正解ラベルのランクまでの正解数 = ランク1～3までの正解数 = 1\n",
    "- なので、Score = 1/3 = 0.33 となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解ラベル [0]\n",
      "スコア [0.33333333]\n"
     ]
    }
   ],
   "source": [
    "# 実際に計算してみる。\n",
    "y_true = np.array([1, 0, 0,])\n",
    "y_score = np.array([0.1, 0.7, 0.2])\n",
    "pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(y_score, y_true)\n",
    "print(\"正解ラベル\", pos_class_indices)\n",
    "print(\"スコア\", precision_at_hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正解ラベルが複数の場合。\n",
    "- クラスがA,B,Cの3種類とする。\n",
    "- 正解ラベル = (A,C), 予測 = (A: 0.7, B: 0.1, 0.2)の場合を例として考える。\n",
    "- Scoreは**正解ラベル**ごとに計算される。\n",
    "\n",
    "\n",
    "- まず正解ラベルAに対するスコアを計算すると、\n",
    "    - ランク化予測 = (A: 1, B: 3, C:2)\n",
    "    - 正解ラベルのランク = 1\n",
    "    - 1～正解ラベルのランクまでの正解数 = ランク1～3までの正解数 = 1\n",
    "- なので、Score = 1/1 = 1.0 となる。\n",
    "\n",
    "\n",
    "- 次に正解ラベルCに対するスコアを計算すると、\n",
    "    - ランク化予測 = (A: 1, B: 3, C:2)\n",
    "    - 正解ラベルのランク = 2\n",
    "    - 1～正解ラベルのランクまでの正解数 = ランク1～2までの正解数 = 2\n",
    "- なので、Score = 2/2 = 1.0 となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解ラベル [0 2]\n",
      "スコア [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 実際に計算してみる。\n",
    "y_true = np.array([1, 0, 1,])\n",
    "y_score = np.array([0.7, 0.1, 0.2])\n",
    "pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(y_score, y_true)\n",
    "print(\"正解ラベル\", pos_class_indices)\n",
    "print(\"スコア\", precision_at_hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "別例\n",
    "\n",
    "- 正解ラベル = A,C, 予測 = (A: 0.1, B: 0.7, 0.2)の場合を例として考える。\n",
    "- Scoreは**正解ラベル**ごとに計算される。\n",
    "\n",
    "\n",
    "- まず正解ラベルAに対するスコアを計算すると、\n",
    "    - ランク化予測 = (A: 3, B: 1, C:2)\n",
    "    - 正解ラベルのランク = 3\n",
    "    - 1～正解ラベルのランクまでの正解数 = ランク1～3までの正解数 = 2  \n",
    "- なので、Score = 2/3 = 0.67 となる。\n",
    "\n",
    "\n",
    "- 次に正解ラベルCに対するスコアを計算すると、\n",
    "    - ランク化予測 = (A: 3, B: 1, C:2)\n",
    "    - 正解ラベルのランク = 2\n",
    "    - 1～正解ラベルのランクまでの正解数 = ランク1～2までの正解数 = 1\n",
    "- なので、Score = 1/2 = 0.5 となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解ラベル [0 2]\n",
      "スコア [0.66666667 0.5       ]\n"
     ]
    }
   ],
   "source": [
    "# 実際に計算してみる。\n",
    "y_true = np.array([1, 0, 1,])\n",
    "y_score = np.array([0.1, 0.7, 0.2])\n",
    "pos_class_indices, precision_at_hits = _one_sample_positive_class_precisions(y_score, y_true)\n",
    "print(\"正解ラベル\", pos_class_indices)\n",
    "print(\"スコア\", precision_at_hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1 のスコア [0.66666667 0.5       ]\n",
      "sample 2 のスコア [1. 1.]\n",
      "各クラスのスコア [0.66666667 1.         0.75      ]\n",
      "各クラスの重み [0.25 0.25 0.5 ]\n",
      "LwLRAP 0.7916666666666666\n"
     ]
    }
   ],
   "source": [
    "# 実際に計算してみる。\n",
    "y_true = np.array([[1, 0, 1,], [0, 1, 1]])\n",
    "y_score = np.array([[0.1, 0.7, 0.2], [0.1, 0.7, 0.2]])\n",
    "_, precision_at_hits1 = _one_sample_positive_class_precisions(y_score[0], y_true[0])\n",
    "print(\"sample 1 のスコア\", precision_at_hits1)\n",
    "_, precision_at_hits2 = _one_sample_positive_class_precisions(y_score[1], y_true[1])\n",
    "print(\"sample 2 のスコア\", precision_at_hits2)\n",
    "score, weight = calculate_per_class_lwlrap(y_true, y_score)\n",
    "print(\"各クラスのスコア\", score)\n",
    "print(\"各クラスの重み\", weight)\n",
    "LwLRAP = (score*weight).sum()\n",
    "print(\"LwLRAP\", LwLRAP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
